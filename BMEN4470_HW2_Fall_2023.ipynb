{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zXZy6DyLjl0S"
   },
   "source": [
    "# **BMEN 4470 - Deep Learning for Biomedical Signal Processing**\n",
    "# **Homework 2: Basics of Modeling Sequences and Temporal Convolution Networks**\n",
    "\n",
    "Due 11:59pm on October 16th, 2023\n",
    "\n",
    "Please include the names of people you've collaborated with here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "9HrJJcnTitXl"
   },
   "outputs": [],
   "source": [
    "#%pip install bunch\n",
    "#Import\n",
    "import sys\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "import scipy.io as sio\n",
    "from bunch import Bunch\n",
    "import torch.optim as optim\n",
    "from pandas import DataFrame\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.nn.utils import weight_norm\n",
    "from os.path import dirname, join as pjoin\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.tsa.arima_process import ArmaProcess\n",
    "from sklearn.metrics import roc_auc_score, precision_score, recall_score, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LXlQA6-13xlb"
   },
   "source": [
    "**Problem 1: ARMA Model** In this question, you need to apply three different Autoregressive Moving Average Model (ARMA) to the given EKG signal. Compare the input and output signals and answering the following questions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AMe0T0yRDnhE"
   },
   "outputs": [],
   "source": [
    "# The EGK signal contains 100 data points\n",
    "EKG_sig = [41.985077,48.505554,17.868908,-17.902781,-25.676805,2.4074743,40.308300,50.589020,22.663403,-16.953960,-32.144905,-31.155527,-23.732307,6.5244060,44.417355,58.700817,60.295696,58.277584,51.427200,24.971256,18.454710,42.659885,28.012609,13.741727,14.357091,15.576780,11.927580,-14.444111,-25.185453,-19.081909,6.6035562,17.284658,17.544495,16.928368,-6.3161540,-14.990187,10.754345,21.378378,-3.1653652,-13.225622,15.521652,54.976814,64.869339,35.326790,-5.0551395,-18.008286,-15.629535,-11.389389,15.224802,52.611454,69.125626,71.429947,69.159081,63.929958,35.759071,-1.0452937,-12.551209,9.9472542,23.483477,29.982676,53.127209,38.299618,26.093702,25.454752,0.92754990,-9.3693218,19.490158,56.732342,40.379166,1.2176796,15.432666,53.198875,38.633102,1.4428799,12.662603,25.239782,24.835445,19.891754,-6.5586896,3.0409441,15.515370,13.531504,6.8291478,-15.963812,0.38266551,33.888634,14.340966,-27.637432,-37.876808,-12.587003,-1.4763706,-1.0964720,20.268143,5.8535609,-29.653194,-16.162226,18.147284,6.5141749,-4.5157704,13.640582]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zGOUQpZrDz0E"
   },
   "source": [
    "**1(a)** Moving Average model only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bFsJ_nSh6qSJ"
   },
   "outputs": [],
   "source": [
    "model_1 = ARIMA(EKG_sig, order=)# put the order here\n",
    "model_fit_1 = model_1.fit()\n",
    "residuals_1 = DataFrame(model_fit_1.resid)\n",
    "\n",
    "# line plot of the results\n",
    "plt.plot(EKG_sig, label='EKG')\n",
    "plt.plot(residuals_1, label='MA')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-rfJzLtkF4CU"
   },
   "source": [
    "**1(b)** Autoregressive model only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1A4YlSVsGMVj"
   },
   "outputs": [],
   "source": [
    "model_2 = ARIMA(EKG_sig, order=)# put the order here\n",
    "model_fit_2 = model_2.fit()\n",
    "residuals_2 = DataFrame(model_fit_2.resid)\n",
    "\n",
    "# line plot of the results\n",
    "plt.plot(EKG_sig, label='EKG')\n",
    "plt.plot(residuals_2, label='AR')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-LWbyVlFG1e_"
   },
   "source": [
    "**1(c)** ARMA model with p = 5, q = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oT5oyayMG1uX"
   },
   "outputs": [],
   "source": [
    "model_3 = ARIMA(EKG_sig, order=)# put the order here\n",
    "model_fit_3 = model_3.fit()\n",
    "residuals_3 = DataFrame(model_fit_3.resid)\n",
    "\n",
    "# line plot of the results\n",
    "plt.plot(EKG_sig, label='EKG')\n",
    "plt.plot(residuals_3, label='ARMA')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IB60UnHtIlvT"
   },
   "source": [
    "**1(d)** What are the differences between those three models? Which model works best for this EKG data? What are the pros and cons of each model? Please list at least one pro and con for each model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q1pBSaRJJbcp"
   },
   "source": [
    "Your Answers:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7BATDuHPsLlj"
   },
   "source": [
    "**Problem 2 Temporal Convolutional Networks** In this question, we will generate a dataset and build a simple TCN to train and test on the dataset. \n",
    "\n",
    "This dataset contains some data sequences: a pair of input sequences and an output. The first sequence within the input pair is composed of numbers randomly sampled from the range [0, 1]. The second input sequence within the input pair is composed of only integers: 0 or 1. This sequence must contain only two integer 1; the rest of the integers are all 0s. The output is the sum of the two values from the first input sequence corresponding to 1s in the second input sequence. \n",
    "\n",
    "For example, one input sequence pair can be [[0, 0.1, 0.2, 0.3, 0.4, 0.5], [0, 0, 0, 1, 1, 0]]. In this case, the final output value should be 0.3 + 0.4 = 0.7. In this example, the length of the data sequence is 6.\n",
    "\n",
    "For the detail of TCN, see the GitHub repo [here](https://github.com/locuslab/TCN/tree/master/TCN/adding_problem)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9_zBwJOusWnZ"
   },
   "outputs": [],
   "source": [
    "# data generator\n",
    "def data_generator(N, seq_length):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        seq_length: Length of the adding problem data\n",
    "        N: # of data in the set\n",
    "    \"\"\"\n",
    "    X_num = torch.rand([N, 1, seq_length])\n",
    "    X_mask = torch.zeros([N, 1, seq_length])\n",
    "    Y = torch.zeros([N, 1])\n",
    "    for i in tqdm(range(N)):\n",
    "        positions = np.random.choice(seq_length, size=2, replace=False)\n",
    "        X_mask[i, 0, positions[0]] = 1\n",
    "        X_mask[i, 0, positions[1]] = 1\n",
    "        Y[i,0] = X_num[i, 0, positions[0]] + X_num[i, 0, positions[1]]\n",
    "    X = torch.cat((X_num, X_mask), dim=1)\n",
    "    return Variable(X), Variable(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BmQsdvIHRxmA"
   },
   "outputs": [],
   "source": [
    "# generate data\n",
    "X_train, Y_train = data_generator(5000, 100)\n",
    "X_test, Y_test = data_generator(100, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Lcxbz3hs_o-S"
   },
   "outputs": [],
   "source": [
    "# define several classes for training.\n",
    "class TCN(nn.Module):\n",
    "    def __init__(self, input_size, output_size, num_channels, kernel_size, dropout):\n",
    "        super(TCN, self).__init__()\n",
    "        self.tcn = TemporalConvNet(input_size, num_channels, kernel_size=kernel_size, dropout=dropout)\n",
    "        self.linear = nn.Linear(num_channels[-1], output_size)\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        self.linear.weight.data.normal_(0, 0.01)\n",
    "\n",
    "    def forward(self, x):\n",
    "        y1 = self.tcn(x)\n",
    "        return self.linear(y1[:, :, -1])\n",
    "\n",
    "\n",
    "class Chomp1d(nn.Module):\n",
    "    def __init__(self, chomp_size):\n",
    "        super(Chomp1d, self).__init__()\n",
    "        self.chomp_size = chomp_size\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x[:, :, :-self.chomp_size].contiguous()\n",
    "\n",
    "class TemporalConvNet(nn.Module):\n",
    "    def __init__(self, num_inputs, num_channels, kernel_size=2, dropout=0.2):\n",
    "        super(TemporalConvNet, self).__init__()\n",
    "        layers = []\n",
    "        num_levels = len(num_channels)\n",
    "        for i in range(num_levels):\n",
    "            dilation_size = 2 ** i\n",
    "            in_channels = num_inputs if i == 0 else num_channels[i-1]\n",
    "            out_channels = num_channels[i]\n",
    "            layers += [TemporalBlock(in_channels, out_channels, kernel_size, stride=1, dilation=dilation_size,\n",
    "                                     padding=(kernel_size-1) * dilation_size, dropout=dropout)]\n",
    "\n",
    "        self.network = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.network(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bf3AG8CWC40F"
   },
   "source": [
    "**2(a)** Build your TCN model below. Your model should contain two convolutional layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mN_krETLCwxY"
   },
   "outputs": [],
   "source": [
    "class TemporalBlock(nn.Module):\n",
    "    def __init__(self, n_inputs, n_outputs, kernel_size, stride, dilation, padding, dropout=0.2):\n",
    "        super(TemporalBlock, self).__init__()\n",
    "        # Your Code:\n",
    "\n",
    "    def init_weights(self):\n",
    "        self.conv1.weight.data.normal_(0, 0.01)\n",
    "        self.conv2.weight.data.normal_(0, 0.01)\n",
    "        if self.downsample is not None:\n",
    "            self.downsample.weight.data.normal_(0, 0.01)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.net(x)\n",
    "        res = x if self.downsample is None else self.downsample(x)\n",
    "        return self.relu(out + res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qmBOwqphE32Z"
   },
   "source": [
    "**2(b)** Set and adjust the training parameters to make the Average Difference you got from your network smaller than 0.008. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2CgQm0n87_AX"
   },
   "outputs": [],
   "source": [
    "# initialize training parameters.\n",
    "args = Bunch()\n",
    "# adjustable parameters\n",
    "args.epochs = # put values here\n",
    "args.ksize = # put values here\n",
    "args.batch_size = # put values here\n",
    "args.lr = # put values here\n",
    "\n",
    "# fix parameters\n",
    "args.cuda = True\n",
    "args.dropout = False\n",
    "args.seq_len = 100\n",
    "args.clip = -1\n",
    "args.levels = 8\n",
    "args.log_interval = 100\n",
    "args.optim = 'Adam'\n",
    "args.nhid = 30\n",
    "args.seed = 112\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OSICsQXAEfqv"
   },
   "source": [
    "Train your model. You need to use GPU for training here. To start a GPU on your Colab, follow the instruction on the slides for this assignment. Please re-run the first block after you set up the GPU. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PXkcUFk9sWaB"
   },
   "outputs": [],
   "source": [
    "# train the model with two conv layers\n",
    "torch.manual_seed(args.seed)\n",
    "if torch.cuda.is_available():\n",
    "    if not args.cuda:\n",
    "        print(\"WARNING: You have a CUDA device, so you should probably run with --cuda\")\n",
    "\n",
    "input_channels = 2\n",
    "n_classes = 1\n",
    "batch_size = args.batch_size\n",
    "seq_length = args.seq_len\n",
    "epochs = args.epochs\n",
    "\n",
    "\n",
    "# Note: We use a very simple setting here (assuming all levels have the same # of channels.\n",
    "channel_sizes = [args.nhid]*args.levels\n",
    "kernel_size = args.ksize\n",
    "dropout = args.dropout\n",
    "model = TCN(input_channels, n_classes, channel_sizes, kernel_size=kernel_size, dropout=dropout)\n",
    "\n",
    "if args.cuda:\n",
    "    model.cuda()\n",
    "    X_train = X_train.cuda()\n",
    "    Y_train = Y_train.cuda()\n",
    "    X_test = X_test.cuda()\n",
    "    Y_test = Y_test.cuda()\n",
    "\n",
    "lr = args.lr\n",
    "optimizer = getattr(optim, args.optim)(model.parameters(), lr=lr)\n",
    "\n",
    "\n",
    "def train(epoch):\n",
    "    global lr\n",
    "    model.train()\n",
    "    batch_idx = 1\n",
    "    total_loss = 0\n",
    "    for i in range(0, X_train.size(0), batch_size):\n",
    "        if i + batch_size > X_train.size(0):\n",
    "            x, y = X_train[i:], Y_train[i:]\n",
    "        else:\n",
    "            x, y = X_train[i:(i+batch_size)], Y_train[i:(i+batch_size)]\n",
    "        optimizer.zero_grad()\n",
    "        output = model(x)\n",
    "        loss = F.mse_loss(output, y)\n",
    "        loss.backward()\n",
    "        if args.clip > 0:\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), args.clip)\n",
    "        optimizer.step()\n",
    "        batch_idx += 1\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        if batch_idx % args.log_interval == 0:\n",
    "            cur_loss = total_loss / args.log_interval\n",
    "            processed = min(i+batch_size, X_train.size(0))\n",
    "            print('Train Epoch: {:2d} [{:6d}/{:6d} ({:.0f}%)]\\tLearning rate: {:.4f}\\tLoss: {:.6f}'.format(\n",
    "                epoch, processed, X_train.size(0), 100.*processed/X_train.size(0), lr, cur_loss))\n",
    "            total_loss = 0\n",
    "\n",
    "\n",
    "def evaluate():\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        output = model(X_test)\n",
    "        test_loss = F.mse_loss(output, Y_test)\n",
    "        print('\\nValidation set: Average loss: {:.6f}\\n'.format(test_loss.item()))\n",
    "        return test_loss.item()\n",
    "\n",
    "\n",
    "for ep in range(1, epochs+1):\n",
    "    train(ep)\n",
    "    tloss = evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IzBGs4L5HJpw"
   },
   "outputs": [],
   "source": [
    "# show the results. You will get full credit if the average differences is less than 0.02\n",
    "preds = model(X_test)\n",
    "\n",
    "total_diff = 0\n",
    "for i,pred in enumerate(preds):\n",
    "    total_diff += np.abs(pred.data.item() - Y_test[i].item())\n",
    "\n",
    "\n",
    "print('Average Difference:', total_diff/len(Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JXArmQQ-FtQO"
   },
   "source": [
    "**2(c)** Now build a TCN model with only one convolutional layer. Use the same parameter you set in 2(b) and train your network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F_B0bVmKsWIK"
   },
   "outputs": [],
   "source": [
    "class TemporalBlock(nn.Module):\n",
    "    def __init__(self, n_inputs, n_outputs, kernel_size, stride, dilation, padding, dropout=0.2):\n",
    "        super(TemporalBlock, self).__init__()\n",
    "        # Your Code:\n",
    "\n",
    "\n",
    "    def init_weights(self):\n",
    "        self.conv1.weight.data.normal_(0, 0.01)\n",
    "        if self.downsample is not None:\n",
    "            self.downsample.weight.data.normal_(0, 0.01)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.net(x)\n",
    "        res = x if self.downsample is None else self.downsample(x)\n",
    "        return self.relu(out + res)\n",
    "\n",
    "\n",
    "# train the model with two conv layers\n",
    "torch.manual_seed(args.seed)\n",
    "if torch.cuda.is_available():\n",
    "    if not args.cuda:\n",
    "        print(\"WARNING: You have a CUDA device, so you should probably run with --cuda\")\n",
    "\n",
    "input_channels = 2\n",
    "n_classes = 1\n",
    "batch_size = args.batch_size\n",
    "seq_length = args.seq_len\n",
    "epochs = args.epochs\n",
    "\n",
    "\n",
    "# Note: We use a very simple setting here (assuming all levels have the same # of channels.\n",
    "channel_sizes = [args.nhid]*args.levels\n",
    "kernel_size = args.ksize\n",
    "dropout = args.dropout\n",
    "model = TCN(input_channels, n_classes, channel_sizes, kernel_size=kernel_size, dropout=dropout)\n",
    "\n",
    "if args.cuda:\n",
    "    model.cuda()\n",
    "    X_train = X_train.cuda()\n",
    "    Y_train = Y_train.cuda()\n",
    "    X_test = X_test.cuda()\n",
    "    Y_test = Y_test.cuda()\n",
    "\n",
    "lr = args.lr\n",
    "optimizer = getattr(optim, args.optim)(model.parameters(), lr=lr)\n",
    "\n",
    "\n",
    "for ep in range(1, epochs+1):\n",
    "    train(ep)\n",
    "    tloss = evaluate()\n",
    "\n",
    "# show the result\n",
    "preds = model(X_test)\n",
    "\n",
    "total_diff = 0\n",
    "for i,pred in enumerate(preds):\n",
    "    total_diff += np.abs(pred.data.item() - Y_test[i].item())\n",
    "\n",
    "\n",
    "print('Average Difference:', total_diff/len(Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kw7ddfgBieTO"
   },
   "source": [
    "**2(d)** Compare the result you get from 2(c) with the average difference you get from 2(b). Which network gives you a better result? Why that network gives a better result? Do you have any suggestions to improve the performance of the network that has poorer performance? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4i2zHicWjlLv"
   },
   "source": [
    "Your Answers:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BSTbPdLmiGFr"
   },
   "source": [
    "**Problem 3: EEGNet** In this question, we will use EEGNet, a compact convolutional network for EEG-based brain-computer interfaces. Your task is to process the given EEG data so that you can train and test the network on the dataset. For more detail about the EEGNet, please see the GitHub repo here:\n",
    "https://github.com/aliasvishnu/EEGNet.\n",
    "\n",
    "The EEG data given in this question are generated. Feel free to print or plot the data if you want to know what the dataset looks like. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eliGBb404rAX"
   },
   "outputs": [],
   "source": [
    "# MOUNTING GOOGLE DRIVE WHERE DATA IS STORED\n",
    "from google.colab import drive\n",
    "drive.mount('/drive', force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ixfh8Xpz42tU"
   },
   "outputs": [],
   "source": [
    "# Import data and save as np.array\n",
    "Data = sio.loadmat('PATH/TO/FILE/X.mat')\n",
    "Label = sio.loadmat('PATH/TO/FILE/Y.mat')\n",
    "Dataset = Data['Data']\n",
    "Labels = Label['Labels']\n",
    "print(Dataset.shape, Labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wOuwUDULsXxH"
   },
   "outputs": [],
   "source": [
    "# define the EEGNet\n",
    "class EEGNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(EEGNet, self).__init__()\n",
    "        self.T = 120\n",
    "        \n",
    "        # Layer 1\n",
    "        self.conv1 = nn.Conv2d(1, 16, (1, 64), padding = 0)\n",
    "        self.batchnorm1 = nn.BatchNorm2d(16, False)\n",
    "        \n",
    "        # Layer 2\n",
    "        self.padding1 = nn.ZeroPad2d((16, 17, 0, 1))\n",
    "        self.conv2 = nn.Conv2d(1, 4, (2, 32))\n",
    "        self.batchnorm2 = nn.BatchNorm2d(4, False)\n",
    "        self.pooling2 = nn.MaxPool2d(2, 4)\n",
    "        \n",
    "        # Layer 3\n",
    "        self.padding2 = nn.ZeroPad2d((2, 1, 4, 3))\n",
    "        self.conv3 = nn.Conv2d(4, 4, (8, 4))\n",
    "        self.batchnorm3 = nn.BatchNorm2d(4, False)\n",
    "        self.pooling3 = nn.MaxPool2d((2, 4))\n",
    "\n",
    "        # FC Layer\n",
    "        # NOTE: This dimension will depend on the number of timestamps per sample in your data.\n",
    "        # here we have 120 timepoints\n",
    "        self.fc1 = nn.Linear(4*2*7, 1)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        # Layer 1\n",
    "        x = F.elu(self.conv1(x))\n",
    "        x = self.batchnorm1(x)\n",
    "        x = F.dropout(x, 0.25)\n",
    "        x = x.permute(0, 3, 1, 2)\n",
    "        \n",
    "        # Layer 2\n",
    "        x = self.padding1(x)\n",
    "        x = F.elu(self.conv2(x))\n",
    "        x = self.batchnorm2(x)\n",
    "        x = F.dropout(x, 0.25)\n",
    "        x = self.pooling2(x)\n",
    "        \n",
    "        # Layer 3\n",
    "        x = self.padding2(x)\n",
    "        x = F.elu(self.conv3(x))\n",
    "        x = self.batchnorm3(x)\n",
    "        x = F.dropout(x, 0.25)\n",
    "        x = self.pooling3(x)\n",
    "        \n",
    "        # FC Layer\n",
    "        x = x.reshape(-1, 4*2*7)\n",
    "        x = torch.sigmoid(self.fc1(x))\n",
    "        return x\n",
    "\n",
    "\n",
    "net = EEGNet()\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(net.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f5LisRGVsXoM"
   },
   "outputs": [],
   "source": [
    "# Define the evaluation function\n",
    "def evaluate(model, X, Y, params = [\"acc\"]):\n",
    "    results = []\n",
    "    batch_size = 50\n",
    "    \n",
    "    predicted = []\n",
    "    \n",
    "    for i in range(int(len(X)/batch_size)):\n",
    "        s = i*batch_size\n",
    "        e = i*batch_size+batch_size\n",
    "        \n",
    "        inputs = Variable(torch.from_numpy(X[s:e]))\n",
    "        pred = model(inputs)\n",
    "        \n",
    "        predicted.append(pred.data.cpu().numpy())\n",
    "        \n",
    "        \n",
    "    inputs = Variable(torch.from_numpy(X))\n",
    "    predicted = model(inputs)\n",
    "    \n",
    "    predicted = predicted.data.cpu().numpy()\n",
    "    \n",
    "    for param in params:\n",
    "        if param == 'acc':\n",
    "            results.append(accuracy_score(Y, np.round(predicted)))\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H9-_OKF_H4L3"
   },
   "source": [
    "**3(a)** Now, reshape the data so you can train it using EEGNet. To train the network, you also need to modify the network parameters to match the dimension of your training data. Please see the image [here](https://github.com/aliasvishnu/EEGNet/blob/master/EEGNet.png) for more information. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W2VckhJizNsg"
   },
   "outputs": [],
   "source": [
    " # Your coode\n",
    "X = \n",
    "Y = \n",
    "print(X.shape, Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a0LaqrLuINkv"
   },
   "source": [
    "**3(b)** Now split the training, evaluation, and testing data. Please make sure you have about 80% for training, about 10% for evaluation, and about 10% for testing. Then train your network on the dataset and test it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6_sj1h6usXcc"
   },
   "outputs": [],
   "source": [
    "# Your Code: \n",
    "# Please name the parameters as names given below in the print function.\n",
    "X_train = \n",
    "y_train = \n",
    "\n",
    "X_val = \n",
    "y_val = \n",
    "\n",
    "X_test = \n",
    "y_test = \n",
    "\n",
    "print(X_train.shape, X_val.shape,X_test.shape)\n",
    "print(y_train.shape, y_val.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZHFpTZAxtXBl"
   },
   "outputs": [],
   "source": [
    "# train and test on your dataset\n",
    "batch_size = 16\n",
    "\n",
    "for epoch in range(40):  # loop over the dataset multiple times\n",
    "    print(\"\\nEpoch \", epoch)\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    for i in range(int(len(X_train)/batch_size-1)):\n",
    "        s = i*batch_size\n",
    "        e = i*batch_size+batch_size\n",
    "        \n",
    "        inputs = torch.from_numpy(X_train[s:e])\n",
    "        labels = torch.FloatTensor(np.array([y_train[s:e]]).T*1.0)\n",
    "        \n",
    "        # wrap them in Variable\n",
    "        inputs, labels = Variable(inputs), Variable(labels)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)   \n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        \n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.data\n",
    "    \n",
    "    # Validation accuracy\n",
    "    params = [\"acc\"]\n",
    "    print(\"Training Loss \", running_loss)\n",
    "    print(\"Train - \", evaluate(net, X_train, y_train, params))\n",
    "    print(\"Validation - \", evaluate(net, X_val, y_val, params))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cOspEmnDmAcO"
   },
   "outputs": [],
   "source": [
    "# print test accuracy\n",
    "print(\"Test - \", evaluate(net, X_test, y_test, params))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lkJ-O-yiI8KN"
   },
   "source": [
    "**3(c)** Now, split the data by 50% training, 40% validation, 10% testing, and retrain your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZtSpZfeVtWvu"
   },
   "outputs": [],
   "source": [
    "# Your Code:\n",
    "X_train = \n",
    "y_train = \n",
    "\n",
    "X_val = \n",
    "y_val = \n",
    "\n",
    "X_test = \n",
    "y_test = \n",
    "\n",
    "print(X_train.shape, X_val.shape,X_test.shape)\n",
    "print(y_train.shape, y_val.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9OAkh5W4o6T7"
   },
   "outputs": [],
   "source": [
    "# train and test on the dataset with 50% training, 40% validation, and 10% test data\n",
    "batch_size = 16\n",
    "\n",
    "for epoch in range(40):  # loop over the dataset multiple times\n",
    "    print(\"\\nEpoch \", epoch)\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    for i in range(int(len(X_train)/batch_size-1)):\n",
    "        s = i*batch_size\n",
    "        e = i*batch_size+batch_size\n",
    "        \n",
    "        inputs = torch.from_numpy(X_train[s:e])\n",
    "        labels = torch.FloatTensor(np.array([y_train[s:e]]).T*1.0)\n",
    "        \n",
    "        # wrap them in Variable\n",
    "        inputs, labels = Variable(inputs), Variable(labels)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)   \n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        \n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.data\n",
    "    \n",
    "    # Validation accuracy\n",
    "    params = [\"acc\", \"auc\", \"fmeasure\"]\n",
    "    print(params)\n",
    "    print(\"Training Loss \", running_loss)\n",
    "    print(\"Train - \", evaluate(net, X_train, y_train, params))\n",
    "    print(\"Validation - \", evaluate(net, X_val, y_val, params))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oO_vOCcupGgV"
   },
   "outputs": [],
   "source": [
    "print(\"Test - \", evaluate(net, X_test, y_test, params))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uuLnQAkCs6OT"
   },
   "source": [
    "**3(d)** Compare the result you get from 3(d) with the test accuracy in 3(c). Which data split method gives you a better result? Why that method gives a better result? What did you learn from this?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0RGiDOnfvsyF"
   },
   "source": [
    "Your Answers:"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "BMEN4470_HW2_Fall_2021.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
